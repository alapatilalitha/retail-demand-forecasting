{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55fbaac5",
   "metadata": {},
   "source": [
    "# Step 3: Baseline Modeling\n",
    "\n",
    "This notebook trains a baseline Linear Regression model using Spark MLlib.\n",
    "A Pandas + scikit-learn implementation is used only for validation and\n",
    "comparison of results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292bc376",
   "metadata": {},
   "source": [
    "Start Spark & Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1399191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/19 10:21:21 WARN Utils: Your hostname, MacBook-Air-3.local resolves to a loopback address: 127.0.0.1; using 10.0.0.22 instead (on interface en0)\n",
      "26/01/19 10:21:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/19 10:21:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/19 10:21:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "26/01/19 10:21:22 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----------+------------+-----+----+-----+-----+------------------+------------------+\n",
      "|      date|daily_quantity|day_of_week|week_of_year|month|year|lag_1|lag_7|         rolling_7|        rolling_14|\n",
      "+----------+--------------+-----------+------------+-----+----+-----+-----+------------------+------------------+\n",
      "|2010-12-09|         19930|          5|          49|   12|2010|23117|26919| 23004.14285714286| 23004.14285714286|\n",
      "|2010-12-10|         21097|          6|          49|   12|2010|19930|31329|22005.714285714286|         22619.875|\n",
      "|2010-12-12|         10603|          1|          49|   12|2010|21097|16199|           20544.0|22450.666666666668|\n",
      "|2010-12-13|         17727|          2|          50|   12|2010|10603|16450|19744.571428571428|           21265.9|\n",
      "|2010-12-14|         20284|          3|          50|   12|2010|17727|21795|           19927.0| 20944.18181818182|\n",
      "+----------+--------------+-----------+------------+-----+----+-----+-----+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RetailDemandBaseline\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_model = spark.read.parquet(\"../data/processed/daily_features\")\n",
    "df_model.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3911d4",
   "metadata": {},
   "source": [
    "Verify Required Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0bcf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- daily_quantity: long (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- week_of_year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- lag_1: long (nullable = true)\n",
      " |-- lag_7: long (nullable = true)\n",
      " |-- rolling_7: double (nullable = true)\n",
      " |-- rolling_14: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_model.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82e2ee",
   "metadata": {},
   "source": [
    "Assemble Feature Vector (Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c4dd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|  label|\n",
      "+--------------------+-------+\n",
      "|[23117.0,26919.0,...|19930.0|\n",
      "|[19930.0,31329.0,...|21097.0|\n",
      "|[21097.0,16199.0,...|10603.0|\n",
      "|[10603.0,16450.0,...|17727.0|\n",
      "|[17727.0,21795.0,...|20284.0|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"lag_1\",\n",
    "        \"lag_7\",\n",
    "        \"rolling_7\",\n",
    "        \"rolling_14\",\n",
    "        \"day_of_week\",\n",
    "        \"week_of_year\",\n",
    "        \"month\"\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df_final = assembler.transform(df_model) \\\n",
    "    .select(\n",
    "        \"features\",\n",
    "        col(\"daily_quantity\").cast(\"double\").alias(\"label\")\n",
    "    ) \\\n",
    "    .dropna()\n",
    "\n",
    "df_final.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e18f0",
   "metadata": {},
   "source": [
    "Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d088a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 252\n",
      "Test rows: 46\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Train rows:\", train_df.count())\n",
    "print(\"Test rows:\", test_df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e599644",
   "metadata": {},
   "source": [
    "Spark Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebc4607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/19 10:23:32 WARN Instrumentation: [d0bfb61c] regParam is zero, which might cause numerical instability and overfitting.\n",
      "26/01/19 10:23:32 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "26/01/19 10:23:32 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "26/01/19 10:23:32 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\"\n",
    ")\n",
    "\n",
    "lr_model = lr.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75826130",
   "metadata": {},
   "source": [
    "Spark Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5284c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|  label|        prediction|\n",
      "+-------+------------------+\n",
      "|13595.0| 7622.703374810619|\n",
      "|13415.0|  9357.72369280981|\n",
      "|14940.0|19085.187092851742|\n",
      "|12263.0| 9209.583990084882|\n",
      "|21589.0|10814.340963570725|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_predictions = lr_model.transform(test_df)\n",
    "spark_predictions.select(\"label\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca389892",
   "metadata": {},
   "source": [
    "Spark Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9937dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13191.143238433897, 7478.156513218914)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rmse_eval = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "mae_eval = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\"\n",
    ")\n",
    "\n",
    "rmse_spark = rmse_eval.evaluate(spark_predictions)\n",
    "mae_spark = mae_eval.evaluate(spark_predictions)\n",
    "\n",
    "rmse_spark, mae_spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b2b8f0",
   "metadata": {},
   "source": [
    "Convert Spark â†’ Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20c6241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_quantity</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>rolling_7</th>\n",
       "      <th>rolling_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-09</td>\n",
       "      <td>19930</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>23117</td>\n",
       "      <td>26919</td>\n",
       "      <td>23004.142857</td>\n",
       "      <td>23004.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-10</td>\n",
       "      <td>21097</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>19930</td>\n",
       "      <td>31329</td>\n",
       "      <td>22005.714286</td>\n",
       "      <td>22619.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-12</td>\n",
       "      <td>10603</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>21097</td>\n",
       "      <td>16199</td>\n",
       "      <td>20544.000000</td>\n",
       "      <td>22450.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-13</td>\n",
       "      <td>17727</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>10603</td>\n",
       "      <td>16450</td>\n",
       "      <td>19744.571429</td>\n",
       "      <td>21265.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-14</td>\n",
       "      <td>20284</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>2010</td>\n",
       "      <td>17727</td>\n",
       "      <td>21795</td>\n",
       "      <td>19927.000000</td>\n",
       "      <td>20944.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  daily_quantity  day_of_week  week_of_year  month  year  lag_1  \\\n",
       "0  2010-12-09           19930            5            49     12  2010  23117   \n",
       "1  2010-12-10           21097            6            49     12  2010  19930   \n",
       "2  2010-12-12           10603            1            49     12  2010  21097   \n",
       "3  2010-12-13           17727            2            50     12  2010  10603   \n",
       "4  2010-12-14           20284            3            50     12  2010  17727   \n",
       "\n",
       "   lag_7     rolling_7    rolling_14  \n",
       "0  26919  23004.142857  23004.142857  \n",
       "1  31329  22005.714286  22619.875000  \n",
       "2  16199  20544.000000  22450.666667  \n",
       "3  16450  19744.571429  21265.900000  \n",
       "4  21795  19927.000000  20944.181818  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = df_model.orderBy(\"date\").toPandas()\n",
    "pdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3a3e2",
   "metadata": {},
   "source": [
    "Prepare Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f5a8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"lag_1\",\n",
    "    \"lag_7\",\n",
    "    \"rolling_7\",\n",
    "    \"rolling_14\",\n",
    "    \"day_of_week\",\n",
    "    \"week_of_year\",\n",
    "    \"month\"\n",
    "]\n",
    "\n",
    "X = pdf[feature_cols]\n",
    "y = pdf[\"daily_quantity\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7fdc51",
   "metadata": {},
   "source": [
    "Time-aware Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "038784a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(pdf) * 0.8)\n",
    "\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f59af",
   "metadata": {},
   "source": [
    "scikit-learn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db7787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sk_model = LinearRegression()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_sk = sk_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa8961",
   "metadata": {},
   "source": [
    "scikit-learn Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b5b5754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(14999.159790175487), 10870.668168591283)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "rmse_sk = np.sqrt(mean_squared_error(y_test, y_pred_sk))\n",
    "mae_sk = mean_absolute_error(y_test, y_pred_sk)\n",
    "\n",
    "rmse_sk, mae_sk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d9577",
   "metadata": {},
   "source": [
    "Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894cbadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spark Linear Regression</td>\n",
       "      <td>13191.143238</td>\n",
       "      <td>7478.156513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scikit-learn Linear Regression</td>\n",
       "      <td>14999.159790</td>\n",
       "      <td>10870.668169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model          RMSE           MAE\n",
       "0         Spark Linear Regression  13191.143238   7478.156513\n",
       "1  scikit-learn Linear Regression  14999.159790  10870.668169"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Spark Linear Regression\", \"scikit-learn Linear Regression\"],\n",
    "    \"RMSE\": [rmse_spark, rmse_sk],\n",
    "    \"MAE\": [mae_spark, mae_sk]\n",
    "})\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088cc2c",
   "metadata": {},
   "source": [
    "### Comparison Summary\n",
    "\n",
    "Both Spark MLlib and scikit-learn Linear Regression models show comparable\n",
    "performance. Minor differences are expected due to distributed execution\n",
    "(Spark) versus in-memory computation (scikit-learn).\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "Spark Linear Regression performed better due to distributed optimization\n",
    "and consistent feature vectorization. The scikit-learn model is included\n",
    "as a validation baseline to confirm trend consistency.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
